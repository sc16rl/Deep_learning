{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (360, 64), (1437,), (360,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数式 API 需要 Input 层，返回一个 placeholder 张量\n",
    "inputs = tf.keras.Input(shape=(64,))\n",
    "x = tf.keras.layers.Dense(units=30, activation='relu')(inputs)\n",
    "outputs = tf.keras.layers.Dense(units=10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1437 samples, validate on 360 samples\n",
      "Epoch 1/20\n",
      "1437/1437 [==============================] - 1s 508us/sample - loss: 7.7930 - acc: 0.1441 - val_loss: 5.1425 - val_acc: 0.2639\n",
      "Epoch 2/20\n",
      "1437/1437 [==============================] - 0s 40us/sample - loss: 4.1644 - acc: 0.3646 - val_loss: 2.9193 - val_acc: 0.4944\n",
      "Epoch 3/20\n",
      "1437/1437 [==============================] - 0s 42us/sample - loss: 2.7070 - acc: 0.5665 - val_loss: 2.0989 - val_acc: 0.6389\n",
      "Epoch 4/20\n",
      "1437/1437 [==============================] - 0s 42us/sample - loss: 1.8676 - acc: 0.6806 - val_loss: 1.4192 - val_acc: 0.6361\n",
      "Epoch 5/20\n",
      "1437/1437 [==============================] - 0s 40us/sample - loss: 1.1329 - acc: 0.7070 - val_loss: 0.8320 - val_acc: 0.7528\n",
      "Epoch 6/20\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.7164 - acc: 0.8003 - val_loss: 0.6493 - val_acc: 0.7861\n",
      "Epoch 7/20\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.5435 - acc: 0.8344 - val_loss: 0.5175 - val_acc: 0.8167\n",
      "Epoch 8/20\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.4459 - acc: 0.8664 - val_loss: 0.4706 - val_acc: 0.8333\n",
      "Epoch 9/20\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.3857 - acc: 0.8907 - val_loss: 0.4013 - val_acc: 0.8500\n",
      "Epoch 10/20\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.3293 - acc: 0.9068 - val_loss: 0.3981 - val_acc: 0.8611\n",
      "Epoch 11/20\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.3002 - acc: 0.9137 - val_loss: 0.3330 - val_acc: 0.8972\n",
      "Epoch 12/20\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.2647 - acc: 0.9269 - val_loss: 0.2999 - val_acc: 0.8944\n",
      "Epoch 13/20\n",
      "1437/1437 [==============================] - 0s 40us/sample - loss: 0.2376 - acc: 0.9346 - val_loss: 0.3009 - val_acc: 0.9028\n",
      "Epoch 14/20\n",
      "1437/1437 [==============================] - 0s 46us/sample - loss: 0.2150 - acc: 0.9388 - val_loss: 0.2822 - val_acc: 0.9056\n",
      "Epoch 15/20\n",
      "1437/1437 [==============================] - 0s 40us/sample - loss: 0.1943 - acc: 0.9443 - val_loss: 0.2583 - val_acc: 0.9250\n",
      "Epoch 16/20\n",
      "1437/1437 [==============================] - 0s 40us/sample - loss: 0.1853 - acc: 0.9457 - val_loss: 0.2563 - val_acc: 0.9194\n",
      "Epoch 17/20\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.1690 - acc: 0.9485 - val_loss: 0.2533 - val_acc: 0.9250\n",
      "Epoch 18/20\n",
      "1437/1437 [==============================] - 0s 40us/sample - loss: 0.1564 - acc: 0.9534 - val_loss: 0.2409 - val_acc: 0.9222\n",
      "Epoch 19/20\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.1425 - acc: 0.9562 - val_loss: 0.2243 - val_acc: 0.9250\n",
      "Epoch 20/20\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.1292 - acc: 0.9589 - val_loss: 0.2310 - val_acc: 0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a42f96e10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 函数式 API 需要指定输入和输出\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# 模型编译和训练和顺序模型一致\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=20,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关于模型保存\n",
    "1. 对于较大的训练任务，保存模型可以方便后续恢复重新使用。\n",
    "2. 保存后的模型可以方便模型部署。\n",
    "\n",
    "TensorFlow 模型一般包含 3 类要素，分别是：模型权重值、模型配置乃至优化器配置。\n",
    "\n",
    "如果只需要保存模型权重值，可以使用 `tf.keras.Model.save_weights` <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#save_weights\"><i class=\"fa fa-external-link-square\" aria-hidden=\"true\"></i></a>，并指定存放路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x1a42a49450>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('./weights/model')  # 保存检查点名称为 model，路径为 ./weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                model.data-00000-of-00001 model.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls './weights/'  # 直接运行查看目录下文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x1a42d8ec10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./weights/model')  # 恢复检查点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下，该方法会以 TensorFlow 检查点文件格式 <a href=\"https://www.tensorflow.org/guide/checkpoints\"><i class=\"fa fa-external-link-square\" aria-hidden=\"true\"></i></a> 保存模型的权重。检查点文件是 TensorFlow 特有的模型权重保存方法，其默认会以每 10 分钟（600 秒）写入一个检查点，训练时间较短则只保存一个检查点。检查点默认情况下只保存 5 个，即模型训练过程中不同时间点的版本状态。\n",
    "\n",
    "我们一般会在大型任务训练时设置检查点保存。这样做的好处在于一旦因为意外情况导致训练终止，TensorFlow 可以加载检查点状态，避免又需要从头开始训练。\n",
    "\n",
    "如果我们需要模型推理，一般情况会使用 `model.save` 保存完整的模型，即包含模型权重值、模型配置乃至优化器配置等。例如，下面将模型存为 Keras HDF5 格式，其为 Keras 多后端实现的默认格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')  # 保存完整模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = tf.keras.models.load_model('model.h5')  # 调用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30)                1950      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 2,260\n",
      "Trainable params: 2,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.8036662e-09, 9.9711108e-01, 8.3323027e-04, 6.6171054e-08,\n",
       "        6.0713497e-05, 5.7099049e-07, 3.2388005e-05, 2.1985049e-07,\n",
       "        1.9616529e-03, 2.3022364e-09],\n",
       "       [1.0787126e-09, 6.1167867e-07, 6.8338180e-05, 1.8049786e-08,\n",
       "        9.3875963e-07, 9.9341053e-01, 5.5667475e-09, 3.4371477e-03,\n",
       "        3.0472213e-03, 3.5199493e-05],\n",
       "       [9.9998474e-01, 2.2993392e-09, 8.0985579e-08, 9.7194264e-10,\n",
       "        3.4024758e-06, 1.5779056e-06, 1.0033179e-05, 2.6977229e-09,\n",
       "        1.0161685e-07, 1.0134030e-10]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model_.predict(X_test[:3])  # 预测前 3 个测试样本\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 5, 0]), array([0.9971111 , 0.9934105 , 0.99998474], dtype=float32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds, axis=1), np.max(preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般情况下，模型的预测是正确的。如果错误可以检查上方模型的评估情况，合理增大 Epoch 以提高模型准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
